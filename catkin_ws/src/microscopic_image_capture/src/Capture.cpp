/* -LICENSE-START-
** Copyright (c) 2013 Blackmagic Design
**  
** Permission is hereby granted, free of charge, to any person or organization 
** obtaining a copy of the software and accompanying documentation (the 
** "Software") to use, reproduce, display, distribute, sub-license, execute, 
** and transmit the Software, and to prepare derivative works of the Software, 
** and to permit third-parties to whom the Software is furnished to do so, in 
** accordance with:
** 
** (1) if the Software is obtained from Blackmagic Design, the End User License 
** Agreement for the Software Development Kit (“EULA”) available at 
** https://www.blackmagicdesign.com/EULA/DeckLinkSDK; or
** 
** (2) if the Software is obtained from any third party, such licensing terms 
** as notified by that third party,
** 
** and all subject to the following:
** 
** (3) the copyright notices in the Software and this entire statement, 
** including the above license grant, this restriction and the following 
** disclaimer, must be included in all copies of the Software, in whole or in 
** part, and all derivative works of the Software, unless such copies or 
** derivative works are solely in the form of machine-executable object code 
** generated by a source language processor.
** 
** (4) THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS 
** OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, 
** FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT 
** SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE 
** FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, 
** ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER 
** DEALINGS IN THE SOFTWARE.
** 
** A copy of the Software is available free of charge at 
** https://www.blackmagicdesign.com/desktopvideo_sdk under the EULA.
** 
** -LICENSE-END-
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <pthread.h>
#include <unistd.h>
#include <fcntl.h>
#include <csignal>
#include <omp.h>

#include <microscopic_image_capture/Capture.h>
#include <microscopic_image_capture/Config.h>

#include "decklink_api/DeckLinkAPI.h"

#include <iostream>
#include <chrono>
#include <cmath>
#include <string>
#include <array>

#include <ros/ros.h>
#include <opencv2/opencv.hpp>
#include <cv_bridge/cv_bridge.h>
#include <image_transport/image_transport.h>
#include <robot_control/ImgShowMsg.h>
#include <robot_control/CImage.h>
#include <robot_control/ROI.h>
#include <sas_datalogger/AddValueMsg.h>
#include <std_msgs/Bool.h>

static pthread_mutex_t	g_sleepMutex;
static pthread_cond_t	g_sleepCond;
static int				g_videoOutputFile {-1};
static int				g_audioOutputFile {-1};
static bool				g_do_exit {false};

static BMDConfig		g_config;

static IDeckLinkInput*	g_deckLinkInput {NULL};

static unsigned long	g_frameCount {0};

DeckLinkCaptureDelegate::DeckLinkCaptureDelegate(ros::NodeHandle& nodehandle) :
    image_transport_(nodehandle), //attach the image transport to the node handle for messages
    m_refCount{1},
    m_pixelFormat{g_config.m_pixelFormat},
    cv_image_yuv{cv::Size(original_w, original_h), CV_8UC2},
    cv_image_bgr{cv::Size(original_w, original_h), CV_8UC3},
    cv_image_ROI{cv::Size(predict_size, predict_size), CV_8UC3},
    cv_image_ROI_resized{cv::Size(predict_size, predict_size), CV_8UC3},
    cv_image_ROI_display{cv::Size(output_size, output_size), CV_8UC3},
    cv_image_show{cv::Size(windowsize_w, windowsize_h), CV_8UC3},
	cv_image_overview_resized{cv::Size(original_w / original_h * output_size, output_size), CV_8UC3},
    resizedImage{cv::Size(original_w, ROI_NN_resize), CV_8UC3}, 
    croppedImage{cv::Size(original_w, ROI_NN_resize), CV_8UC3}    
{
    // ROS publishers
	publisher_compressed_frame = nodehandle.advertise<robot_control::CImage>(("microscope/compressed_frame"), 1);
    publisher_ROI_frame = nodehandle.advertise<robot_control::ROI>("microscope/capture", 1);
	publisher_overview_frame = image_transport_.advertise(std::string("img_show/overview"), 1);

    // ROS subscribers
	subscriber_roi_parameter = nodehandle.subscribe("predict/ROI_parameter", 10, &DeckLinkCaptureDelegate::_get_ROI_parameter, this);
    subscriber_tip_positions = nodehandle.subscribe("predict/tip_positions", 10, &DeckLinkCaptureDelegate::_get_tip_positions, this);
    subscriber_predicted_distances = nodehandle.subscribe("predict/distances", 10, &DeckLinkCaptureDelegate::_get_predicted_distances, this);
    subscriber_contact_reporter = nodehandle.subscribe("arduino/contact", 10, &DeckLinkCaptureDelegate::_get_contact_reporter, this);
    subscriber_positioning_points = nodehandle.subscribe("predict/positioning_points", 10, &DeckLinkCaptureDelegate::_get_positioning_points, this);
    subscriber_planar_error = nodehandle.subscribe("predict/planar_error", 10, &DeckLinkCaptureDelegate::_get_planar_error, this);
    subscriber_current_step = nodehandle.subscribe("predict/current_step", 10, &DeckLinkCaptureDelegate::_get_current_step, this);
}

ULONG DeckLinkCaptureDelegate::AddRef(void)
{
	return __sync_add_and_fetch(&m_refCount, 1);
}

ULONG DeckLinkCaptureDelegate::Release(void)
{
	int32_t newRefValue {__sync_sub_and_fetch(&m_refCount, 1)};
	if (newRefValue == 0)
	{
		delete this;
		return 0;
	}
	return newRefValue;
}

HRESULT DeckLinkCaptureDelegate::VideoInputFrameArrived(IDeckLinkVideoInputFrame* videoFrame, IDeckLinkAudioInputPacket* audioFrame)
{
/*
* This node retains the full resolution frame as it is too expensive to publish the full image. Downscaling reduces data published and results in faster NN.
* 
* General workflow of capture node to process ROI and keypoints within:
* Capture.cpp retrieves frame & downscales (for predict) --cframe.msg--> ROI_predict_node predicts ROI center/size and point on instrument 
* --msg_ROI_parameter--> Capture.cpp extracts ROI & downscales --ROI_msg--> keypoint_predict_node predicts intrument tip and shadow 
* --msg_tip--> Capture.cpp displays image on screen with markup
*/
//    ros::Time start = ros::Time::now();
	// Handle Video Frame
	if (videoFrame)
	{
		if (videoFrame->GetFlags() & bmdFrameHasNoInputSource)
		{
			printf("Frame received (#%lu) - No input signal detected\n", g_frameCount);
		}
		else
		{
			image_width = videoFrame->GetWidth();
            image_height = videoFrame->GetHeight();

            // Fetch video frame, convert to OpenCV YUV and BGR formats
			void* buffer;
            videoFrame->GetBytes(&buffer);
            cv_image_yuv = cv::Mat{image_height, image_width, CV_8UC2, buffer};
            cv::cvtColor(cv_image_yuv, cv_image_bgr, cv::COLOR_YUV2BGR_UYVY);

			// Parallelize the image resizing
			#pragma omp parallel sections
			{
				#pragma omp section 
				{
					cv::resize(cv_image_ROI, cv_image_ROI_resized, cv::Size{predict_size, predict_size});  // Resize for ROI NN
				}
				#pragma omp section 
				{
					if (predict_size == ROI_display_size) {
						cv_image_ROI_display = cv_image_ROI_resized.clone();
					} else {
						cv::resize(cv_image_ROI, cv_image_ROI_display, cv::Size{ROI_display_size, ROI_display_size});
					}
				}
			}

			// Display message on first iteration of loop
			if (first_iteration) {
				std::cout << "Displaying target points. Press any key to continue..." << std::endl;
				first_iteration = false;
			}

			if (keypoint_message) {
				std::cout << "Displaying ROI and keypoints" << std::endl;
				keypoint_message = false;
			}
		
			// Capture only target points until user presses a key, then capture keypoints
			if (initial_processing) {  
				targetImageCapture();  // Capture the target points

				int keypress = cv::waitKey(1);  // Wait for a keypress
				if (keypress != -1) {
					initial_processing = false;
					keypoint_message = true;
				}
			} else {
				keypointImageCapture();  // Capture the keypoints
			}

            // Display the images on the screen and mark up
            for (const auto& point : target_points) {									   // Draw the target points
				cv::circle(cv_image_bgr, point, 10, cv::Scalar{0, 255, 255}, -1);
			}
			cv::resize(cv_image_bgr, cv_image_show,cv::Size(windowsize_w, windowsize_h));  // Resize for display
			cv::rectangle(cv_image_show, cv::Point{2, windowsize_h - ROI_display_size - 2}, cv::Point{ROI_display_size + 2, windowsize_h - 2}, cv::Scalar{255, 0, 0}, 10);
            cv_image_ROI_display.copyTo(cv_image_show(ROI_display_region));                // Copy the ROI image to the display image

            // Display text information on the screen
			if (contact) {
                cv::putText(cv_image_show, "Contact!!", cv::Point(1300, 100), cv::FONT_HERSHEY_SIMPLEX, 3, cv::Scalar{0, 255, 0}, 5, cv::LINE_AA);
            }

            cv::putText(cv_image_show, "planar_error: " + std::to_string(planar_error), cv::Point{1500, 150}, cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar{0, 255, 0}, 3, cv::LINE_AA);
            cv::putText(cv_image_show, "shaft_dis: " + std::to_string(shaft_dis), cv::Point{1500, 200}, cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar{0, 255, 0}, 3, cv::LINE_AA);
            cv::putText(cv_image_show, "tip_dis: " + std::to_string(tip_dis), cv::Point{1500, 250}, cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar{0, 255, 0}, 3, cv::LINE_AA);
            cv::putText(cv_image_show, "ROI_size: " + std::to_string(ROI_half_dis * 2), cv::Point{1500, 300}, cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar{0, 255, 0}, 3, cv::LINE_AA);
            cv::putText(cv_image_show, "current_step: " + current_step, cv::Point{50, 50}, cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar{0, 255, 0}, 3, cv::LINE_AA);

            cv::namedWindow("microscope", cv::WINDOW_NORMAL);
            cv::setWindowProperty("microscope", cv::WND_PROP_FULLSCREEN, cv::WINDOW_FULLSCREEN);
            cv::imshow("microscope", cv_image_show);
            key = cv::waitKey(1);

            ros::spinOnce();
		}
		g_frameCount++;
	}
    return S_OK;
}

void DeckLinkCaptureDelegate::targetImageCapture()
{
	cv::resize(cv_image_bgr, cv_image_overview_resized, cv::Size{resize_width, output_size});  // Resize for overview frame

	// Prepare and publish the overview image
	overview_image_msg = cv_bridge::CvImage{std_msgs::Header(), "bgr8", cv_image_overview_resized}.toImageMsg();
	overview_image_msg->header.stamp = ros::Time::now();
	publisher_overview_frame.publish(overview_image_msg);
}

void DeckLinkCaptureDelegate::keypointImageCapture()
{
	// Resize the image for sending to ROI predictor
	auto [croppedImage, roi_dimensions] = preprocessImageForROI<std::array<int,6>>(cv_image_bgr, ROI_NN_resize);

	// Prepare the cframe message for publishing and publish
	cframe_image_msg = cv_bridge::CvImage{std_msgs::Header(), "bgr8", croppedImage}.toImageMsg();
	cframe_image_msg->header.stamp = ros::Time::now();
	cframe_msg.cframe_image = *cframe_image_msg;	 	    // Copy the compressed image into message
	cframe_msg.cframe_values.assign(roi_dimensions.begin(), roi_dimensions.end()); // Copy the ROI dimensions into message
	publisher_compressed_frame.publish(cframe_msg);  // Publish the cframe message

	// Calculate ROI for processing
	left_top = cv::Point{ROI_center.x - ROI_half_dis, ROI_center.y - ROI_half_dis};
	right_bottom = cv::Point{ROI_center.x + ROI_half_dis, ROI_center.y + ROI_half_dis};
	ROI_region = cv::Rect{left_top.x, left_top.y, 2 * ROI_half_dis, 2 * ROI_half_dis};
	cv_image_ROI = cv::Mat{cv_image_bgr, ROI_region};

	// Prepare and publish the ROI message for keypoint detection
	ROI_image_msg = cv_bridge::CvImage{std_msgs::Header(), "bgr8", cv_image_ROI_resized}.toImageMsg();
	ROI_image_msg->header.stamp = ros::Time::now();
	ROI_msg.roi_image = *ROI_image_msg;   // Copy the ROI image into message
	roi_values = {ROI_center.x, ROI_center.y, ROI_half_dis, point_instrument.x, point_instrument.y};
	ROI_msg.roi_values.assign(roi_values.begin(), roi_values.end());  // Copy the values from the array to msg
	publisher_ROI_frame.publish(ROI_msg);

	// Draw the ROI and keypoints on the overview image
	cv::rectangle(cv_image_bgr, left_top, right_bottom, cv::Scalar{0, 255, 0}, 10);   // Draw the ROI rectangle
	cv::circle(cv_image_bgr, instrument_tip_overall, 10, cv::Scalar{0, 0, 255}, -1);  // Draw the instrument tip
	cv::circle(cv_image_bgr, shaft_point_overall, 10, cv::Scalar{255, 255, 0}, -1);   // Draw the shaft point

	// Draw the keypoints on the ROI image
	cv::circle(cv_image_ROI_display, instrument_tip, 5, cv::Scalar{0, 0, 255}, -1);  // Draw the instrument tip
	cv::circle(cv_image_ROI_display, shadow_tip, 5, cv::Scalar{255, 0, 0}, -1);      // Draw the shadow tip
	// cv::circle(cv_image_ROI_display, shaft_point, 5, cv::Scalar{0, 0, 255}, -1);  // Draw the shaft point
	cv::line(cv_image_ROI_display, shaft_point, instrument_tip, cv::Scalar{0, 0, 255}, 3, -1);  // Draw the shaft line
}

HRESULT DeckLinkCaptureDelegate::VideoInputFormatChanged(BMDVideoInputFormatChangedEvents events, IDeckLinkDisplayMode *mode, BMDDetectedVideoInputFormatFlags formatFlags)
{
	// This only gets called if bmdVideoInputEnableFormatDetection was set
	// when enabling video input
	HRESULT	result;
	char*	displayModeName = NULL;
	BMDPixelFormat	pixelFormat = m_pixelFormat;
	
	if (events & bmdVideoInputColorspaceChanged)
	{
		// Detected a change in colorspace, change pixel format to match detected format
		if (formatFlags & bmdDetectedVideoInputRGB444)
			pixelFormat = bmdFormat10BitRGB;
		else if (formatFlags & bmdDetectedVideoInputYCbCr422)
			pixelFormat = (g_config.m_pixelFormat == bmdFormat8BitYUV) ? bmdFormat8BitYUV : bmdFormat10BitYUV;
		else
			goto bail;
	}

	// Restart streams if either display mode or pixel format have changed
	if ((events & bmdVideoInputDisplayModeChanged) || (m_pixelFormat != pixelFormat))
	{
		mode->GetName((const char**)&displayModeName);
		printf("Video format changed to %s %s\n", displayModeName, formatFlags & bmdDetectedVideoInputRGB444 ? "RGB" : "YUV");

		if (displayModeName)
			free(displayModeName);

		if (g_deckLinkInput)
		{
			g_deckLinkInput->StopStreams();

			result = g_deckLinkInput->EnableVideoInput(mode->GetDisplayMode(), pixelFormat, g_config.m_inputFlags);
			if (result != S_OK)
			{
				fprintf(stderr, "Failed to switch video mode\n");
				goto bail;
			}

			g_deckLinkInput->StartStreams();
		}

		m_pixelFormat = pixelFormat;
	}

bail:
	return S_OK;
}

template <typename Container>
std::pair<cv::Mat, Container> DeckLinkCaptureDelegate::preprocessImageForROI(const cv::Mat& inputImage, const int& ROI_NN_resize) {

    // Resize the image for sending to ROI predictor
    int resizeWidth = ROI_NN_resize * original_w / original_h;
    cv::resize(inputImage, resizedImage, cv::Size{resizeWidth, ROI_NN_resize});

    // Crop out image if size is not divisible by the stride of 16
    int cropHeight = ROI_NN_resize % 16;
    int cropWidth = resizeWidth % 16;
    int cropHeightTop = cropHeight / 2;
    int cropHeightBottom = cropHeight - cropHeightTop;
    int cropWidthLeft = cropWidth / 2;
    int cropWidthRight = cropWidth - cropWidthLeft;

    cv::Rect roi{cropWidthLeft, cropHeightTop, resizeWidth - cropWidthLeft - cropWidthRight, ROI_NN_resize - cropHeightTop - cropHeightBottom};
    croppedImage = resizedImage(roi);

    // Prepare ROI dimensions
    roi_dimensions = {resizeWidth, ROI_NN_resize, cropWidthLeft, cropHeightTop, roi.width, roi.height};

    return {croppedImage, roi_dimensions};
}

static void sigfunc(int signum)
{
	if (signum == SIGINT || signum == SIGTERM)
		g_do_exit = true;

	pthread_cond_signal(&g_sleepCond);
}

void DeckLinkCaptureDelegate::_get_ROI_parameter(const robot_control::ImgShowMsg::ConstPtr &msg)
{
    ROI_center = cv::Point(msg->value[0], msg->value[1]);
    ROI_half_dis = msg->value[2];
	point_instrument = cv::Point(msg->value[3], msg->value[4]);
	shaft_point_overall = cv::Point(msg->value[5], msg->value[6]);
}

void DeckLinkCaptureDelegate::_get_tip_positions(const sas_datalogger::AddValueMsg::ConstPtr &msg)
{
    instrument_tip = cv::Point(msg->value[1], msg->value[0]);
	shadow_tip = cv::Point(msg->value[3], msg->value[2]);
	shaft_point = cv::Point(msg->value[5], msg->value[4]);
	instrument_tip_overall = cv::Point(msg->value[6], msg->value[7]);
}

void DeckLinkCaptureDelegate::_get_predicted_distances(const robot_control::ImgShowMsg::ConstPtr &msg)
{
    tip_dis = msg->value[0];
    shaft_dis = msg->value[1];
}

void DeckLinkCaptureDelegate::_get_contact_reporter(const std_msgs::Bool::ConstPtr &msg)
{
    contact = msg->data;
}

void DeckLinkCaptureDelegate::_get_positioning_points(const sas_datalogger::AddValueMsg::ConstPtr &msg)
{
	// Store the points as a array of cv::Point
	std::size_t index {0};
	for (auto& point : target_points) {
    	point.x = msg->value[index++];
    	point.y = msg->value[index++];
	}

	// Store the radii as a array of cv::Point
	index = 10;  // Ensure the start index for radii in msg->value
	for (auto& radius : radii) {
    	radius = msg->value[index++];
	}
}

void DeckLinkCaptureDelegate::_get_planar_error(const sas_datalogger::AddValueMsg::ConstPtr &msg)
{
    planar_error = msg->value[0];
}

void DeckLinkCaptureDelegate::_get_current_step(const std_msgs::String::ConstPtr &msg)
{
    current_step = msg->data;
}

int main(int argc, char **argv)
{
	HRESULT							result;
	int								exitStatus = 1;

	IDeckLinkIterator*				deckLinkIterator = NULL;
	IDeckLink*						deckLink = NULL;

	IDeckLinkProfileAttributes*		deckLinkAttributes = NULL;
	bool							formatDetectionSupported;
	int64_t							duplexMode;

	IDeckLinkDisplayMode*			displayMode = NULL;
	char*							displayModeName = NULL;
	bool							supported;

	DeckLinkCaptureDelegate*		delegate = NULL;

	pthread_mutex_init(&g_sleepMutex, NULL);
	pthread_cond_init(&g_sleepCond, NULL);

	signal(SIGINT, sigfunc);
	signal(SIGTERM, sigfunc);
	signal(SIGHUP, sigfunc);

    ros::init (argc, argv, "microscope", ros::init_options::NoSigintHandler);
    ros::NodeHandle nodehandle;

	// Process the command line arguments
    if (!g_config.ParseArguments(argc, argv))
	{
		g_config.DisplayUsage(exitStatus);
		goto bail;
	}

	// Get the DeckLink device
	deckLink = g_config.GetSelectedDeckLink();
	if (deckLink == NULL)
	{
		fprintf(stderr, "Unable to get DeckLink device %u\n", g_config.m_deckLinkIndex);
		goto bail;
	}

	result = deckLink->QueryInterface(IID_IDeckLinkProfileAttributes, (void**)&deckLinkAttributes);
	if (result != S_OK)
	{
		fprintf(stderr, "Unable to get DeckLink attributes interface\n");
		goto bail;
	}

	// Check the DeckLink device is active
	result = deckLinkAttributes->GetInt(BMDDeckLinkDuplex, &duplexMode);
	if ((result != S_OK) || (duplexMode == bmdDuplexInactive))
	{
		fprintf(stderr, "The selected DeckLink device is inactive\n");
		goto bail;
	}

	// Get the input (capture) interface of the DeckLink device
	result = deckLink->QueryInterface(IID_IDeckLinkInput, (void**)&g_deckLinkInput);
	if (result != S_OK)
	{
		fprintf(stderr, "The selected device does not have an input interface\n");
		goto bail;
	}

	// Get the display mode
	if (g_config.m_displayModeIndex == -1)
	{
		// Check the card supports format detection
		result = deckLinkAttributes->GetFlag(BMDDeckLinkSupportsInputFormatDetection, &formatDetectionSupported);
		if (result != S_OK || !formatDetectionSupported)
		{
			fprintf(stderr, "Format detection is not supported on this device\n");
			goto bail;
		}

		g_config.m_inputFlags |= bmdVideoInputEnableFormatDetection;
	}

	displayMode = g_config.GetSelectedDeckLinkDisplayMode(deckLink);

	if (displayMode == NULL)
	{
		fprintf(stderr, "Unable to get display mode %d\n", g_config.m_displayModeIndex);
		goto bail;
	}

	// Get display mode name
	result = displayMode->GetName((const char**)&displayModeName);
	if (result != S_OK)
	{
		displayModeName = (char *)malloc(32);
		snprintf(displayModeName, 32, "[index %d]", g_config.m_displayModeIndex);
	}

	// Check display mode is supported with given options
	result = g_deckLinkInput->DoesSupportVideoMode(bmdVideoConnectionUnspecified, displayMode->GetDisplayMode(), g_config.m_pixelFormat, bmdNoVideoInputConversion, bmdSupportedVideoModeDefault, NULL, &supported);
	if (result != S_OK)
		goto bail;

	if (! supported)
	{
		fprintf(stderr, "The display mode %s is not supported with the selected pixel format\n", displayModeName);
		goto bail;
	}

	if (g_config.m_inputFlags & bmdVideoInputDualStream3D)
	{
		if (!(displayMode->GetFlags() & bmdDisplayModeSupports3D))
		{
			fprintf(stderr, "The display mode %s is not supported with 3D\n", displayModeName);
			goto bail;
		}
	}

	// Print the selected configuration
	g_config.DisplayConfiguration();

	// Configure the capture callback
    delegate = new DeckLinkCaptureDelegate(nodehandle);
	g_deckLinkInput->SetCallback(delegate);

	// Open output files
	if (g_config.m_videoOutputFile != NULL)
	{
		g_videoOutputFile = open(g_config.m_videoOutputFile, O_WRONLY|O_CREAT|O_TRUNC, 0664);
		if (g_videoOutputFile < 0)
		{
			fprintf(stderr, "Could not open video output file \"%s\"\n", g_config.m_videoOutputFile);
			goto bail;
		}
	}

	if (g_config.m_audioOutputFile != NULL)
	{
		g_audioOutputFile = open(g_config.m_audioOutputFile, O_WRONLY|O_CREAT|O_TRUNC, 0664);
		if (g_audioOutputFile < 0)
		{
			fprintf(stderr, "Could not open audio output file \"%s\"\n", g_config.m_audioOutputFile);
			goto bail;
		}
	}

	// Block main thread until signal occurs
    while (!g_do_exit)
	{
            // Start capturing
            result = g_deckLinkInput->EnableVideoInput(displayMode->GetDisplayMode(), g_config.m_pixelFormat, g_config.m_inputFlags);
            if (result != S_OK)
            {
                    fprintf(stderr, "Failed to enable video input. Is another application using the card?\n");
                    goto bail;
            }

            result = g_deckLinkInput->EnableAudioInput(bmdAudioSampleRate48kHz, g_config.m_audioSampleDepth, g_config.m_audioChannels);
            if (result != S_OK)
                    goto bail;

            result = g_deckLinkInput->StartStreams();
            if (result != S_OK)
                    goto bail;

            // All Okay.
            exitStatus = 0;

            pthread_mutex_lock(&g_sleepMutex);
            pthread_cond_wait(&g_sleepCond, &g_sleepMutex);
            pthread_mutex_unlock(&g_sleepMutex);

            fprintf(stderr, "Stopping Capture\n");
            g_deckLinkInput->StopStreams();
            g_deckLinkInput->DisableAudioInput();
            g_deckLinkInput->DisableVideoInput();
	}

bail:
	if (g_videoOutputFile != 0)
		close(g_videoOutputFile);

	if (g_audioOutputFile != 0)
		close(g_audioOutputFile);

	if (displayModeName != NULL)
		free(displayModeName);

	if (displayMode != NULL)
		displayMode->Release();

	if (delegate != NULL)
		delegate->Release();

	if (g_deckLinkInput != NULL)
	{
		g_deckLinkInput->Release();
		g_deckLinkInput = NULL;
	}

	if (deckLinkAttributes != NULL)
		deckLinkAttributes->Release();

	if (deckLink != NULL)
		deckLink->Release();

	if (deckLinkIterator != NULL)
		deckLinkIterator->Release();

	return exitStatus;
}
